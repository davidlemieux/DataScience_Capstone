my_ss <- paste(all_sub_source[(nb_words-allpos+1):nb_words],collapse =" ")
allpos=1
if (length(which(rownames(my_sg)==my_ss)!=0)){
my_pred <- sort(my_sg[my_ss,],decreasing = T)[1:4]
my_pred <- data.frame("words"=names(my_pred),"prob"=my_pred,row.names = seq(length(my_pred)))
if (nrow(all_pred) ==0){
all_pred <- my_pred
} else{all_pred <- rbind(all_pred,my_pred)}
}
my_pred
if (nrow(all_pred) ==0){
all_pred <- my_pred
} else{all_pred <- rbind(all_pred,my_pred)}
all_pred
allpos=2
my_sg <- eval(as.name(paste("g_",allpos,sep="")))
my_ss <- paste(all_sub_source[(nb_words-allpos+1):nb_words],collapse =" ")
if (length(which(rownames(my_sg)==my_ss)!=0)){
my_pred <- sort(my_sg[my_ss,],decreasing = T)[1:4]
my_pred <- data.frame("words"=names(my_pred),"prob"=my_pred,row.names = seq(length(my_pred)))
if (nrow(all_pred) ==0){
all_pred <- my_pred
} else{all_pred <- rbind(all_pred,my_pred)}
}
my_pred
all_pred
all_pred <- all_pred %>% group_by(words)%>% summarise("prob"=sum(prob)) %>%arrange(desc(prob))
all_pred
allpos=4
my_sg <- eval(as.name(paste("g_",allpos,sep="")))
my_ss <- paste(all_sub_source[(nb_words-allpos+1):nb_words],collapse =" ")
if (length(which(rownames(my_sg)==my_ss)!=0)){
my_pred <- sort(my_sg[my_ss,],decreasing = T)[1:4]
my_pred <- data.frame("words"=names(my_pred),"prob"=my_pred,row.names = seq(length(my_pred)))
if (nrow(all_pred) ==0){
all_pred <- my_pred
} else{all_pred <- rbind(all_pred,my_pred)}
}
all_pred <- all_pred %>% group_by(words)%>% summarise("prob"=sum(prob)) %>%arrange(desc(prob))
all_pred
all_pred <- all_pred[1:4]
all_pred <- all_pred[1:4,]
all_pred
word_pred <- function(my_source,g_1,g_2,g_3,g_4){
all_sub_source <- unlist(clean_text_DL(my_source))
nb_words <- length(all_sub_source)
cores=detectCores()
cl <- makeCluster(cores[1]-1)
registerDoParallel(cl)
all_pred <- data.frame()
for (allpos in seq(1,min(nb_words,4))) {
my_sg <- eval(as.name(paste("g_",allpos,sep="")))
my_ss <- paste(all_sub_source[(nb_words-allpos+1):nb_words],collapse =" ")
if (length(which(rownames(my_sg)==my_ss)!=0)){
my_pred <- sort(my_sg[my_ss,],decreasing = T)[1:4]
my_pred <- data.frame("words"=names(my_pred),"prob"=my_pred,row.names = seq(length(my_pred)))
if (nrow(all_pred) ==0){
all_pred <- my_pred
} else{all_pred <- rbind(all_pred,my_pred)}
}
}
stopCluster(cl)
all_pred <- all_pred %>% group_by(words)%>% summarise("prob"=sum(prob)) %>%arrange(desc(prob))
all_pred <- all_pred[1:4,]
return(all_pred)
}
my_source <- "do you know why"
yo <- word_pred(my_source,g_1,g_2,g_3,g_4)
yo
#Calling of the different database
g_1 <- readMM("./DataBase/Matrix/unigram_network.mtx")
uni_name <- readLines("./DataBase/Matrix/unigram_row_name.txt")
rownames(g_1) <- uni_name
colnames(g_1) <- uni_name
g_2 <- readMM("./DataBase/Matrix/bigram_network.mtx")
bigram_name <- readLines("./DataBase/Matrix/bigram_row_name.txt")
rownames(g_2) <- bigram_name
colnames(g_2) <- bigram_name
g_3<- readMM("./DataBase/Matrix/trigram_network.mtx")
trigram_name <- readLines("./DataBase/Matrix/trigram_row_name.txt")
rownames(g_3) <- trigram_name
colnames(g_3) <- trigram_name
g_4 <- readMM("./DataBase/Matrix/quadrigram_network.mtx")
quadrigram_name <- readLines("./DataBase/Matrix/quadrigram_row_name.txt")
rownames(g_4) <- quadrigram_name
colnames(g_4) <- quadrigram_name
remove(uni_name,bigram_name,trigram_name,quadrigram_name)
clean_text_DL <- function(my_string){
my_string <- gsub(x=my_string,pattern = "<.*>|@", replacement = "")
my_string <- gsub(x=my_string,"([_])\\1+","\\1", replacement="")
my_string <- quanteda::tokens(my_string,what="word",remove_numbers=T,
remove_punct=T, remove_symbols=T,remove_hyphens=T)
my_string <- quanteda::tokens_tolower(my_string)
my_string <- tokens_wordstem(my_string,language = "english")
my_cleaned_string  <- my_string
return(my_cleaned_string)
}
word_pred <- function(my_source,g_1,g_2,g_3,g_4){
all_sub_source <- unlist(clean_text_DL(my_source))
nb_words <- length(all_sub_source)
cores=detectCores()
cl <- makeCluster(cores[1]-1)
registerDoParallel(cl)
all_pred <- data.frame()
for (allpos in seq(1,min(nb_words,4))) {
my_sg <- eval(as.name(paste("g_",allpos,sep="")))
my_ss <- paste(all_sub_source[(nb_words-allpos+1):nb_words],collapse =" ")
if (length(which(rownames(my_sg)==my_ss)!=0)){
my_pred <- sort(my_sg[my_ss,],decreasing = T)[1:4]
my_pred <- data.frame("words"=names(my_pred),"prob"=my_pred,row.names = seq(length(my_pred)))
if (nrow(all_pred) ==0){
all_pred <- my_pred
} else{all_pred <- rbind(all_pred,my_pred)}
}
}
stopCluster(cl)
all_pred <- all_pred %>% group_by(words)%>% summarise("prob"=sum(prob)) %>%arrange(desc(prob))
all_pred <- all_pred[1:4,]
return(all_pred)
}
my_source <- "do you know why"
yo <- word_pred(my_source,g_1,g_2,g_3,g_4)
yo
import_data <- function(){
g_1 <- readMM("./DataBase/Matrix/unigram_network.mtx")
uni_name <- readLines("./DataBase/Matrix/unigram_row_name.txt")
rownames(g_1) <- uni_name
colnames(g_1) <- uni_name
g_2 <- readMM("./DataBase/Matrix/bigram_network.mtx")
bigram_name <- readLines("./DataBase/Matrix/bigram_row_name.txt")
rownames(g_2) <- bigram_name
colnames(g_2) <- bigram_name
g_3<- readMM("./DataBase/Matrix/trigram_network.mtx")
trigram_name <- readLines("./DataBase/Matrix/trigram_row_name.txt")
rownames(g_3) <- trigram_name
colnames(g_3) <- trigram_name
g_4 <- readMM("./DataBase/Matrix/quadrigram_network.mtx")
quadrigram_name <- readLines("./DataBase/Matrix/quadrigram_row_name.txt")
rownames(g_4) <- quadrigram_name
colnames(g_4) <- quadrigram_name
remove(uni_name,bigram_name,trigram_name,quadrigram_name)
}
clean_text_DL <- function(my_string){
my_string <- gsub(x=my_string,pattern = "<.*>|@", replacement = "")
my_string <- gsub(x=my_string,"([_])\\1+","\\1", replacement="")
my_string <- quanteda::tokens(my_string,what="word",remove_numbers=T,
remove_punct=T, remove_symbols=T,remove_hyphens=T)
my_string <- quanteda::tokens_tolower(my_string)
my_string <- tokens_wordstem(my_string,language = "english")
my_cleaned_string  <- my_string
return(my_cleaned_string)
}
word_pred <- function(my_source,g_1,g_2,g_3,g_4){
all_sub_source <- unlist(clean_text_DL(my_source))
nb_words <- length(all_sub_source)
cores=detectCores()
cl <- makeCluster(cores[1]-1)
registerDoParallel(cl)
all_pred <- data.frame()
for (allpos in seq(1,min(nb_words,4))) {
my_sg <- eval(as.name(paste("g_",allpos,sep="")))
my_ss <- paste(all_sub_source[(nb_words-allpos+1):nb_words],collapse =" ")
if (length(which(rownames(my_sg)==my_ss)!=0)){
my_pred <- sort(my_sg[my_ss,],decreasing = T)[1:4]
my_pred <- data.frame("words"=names(my_pred),"prob"=my_pred,row.names = seq(length(my_pred)))
if (nrow(all_pred) ==0){
all_pred <- my_pred
} else{all_pred <- rbind(all_pred,my_pred)}
}
}
stopCluster(cl)
all_pred <- all_pred %>% group_by(words)%>% summarise("prob"=sum(prob)) %>%arrange(desc(prob))
all_pred <- all_pred[1:4,]
return(all_pred)
}
import_data()
import_data <- function(){
g_1 <- readMM("./DataBase/Matrix/unigram_network.mtx")
uni_name <- readLines("./DataBase/Matrix/unigram_row_name.txt")
rownames(g_1) <- uni_name
colnames(g_1) <- uni_name
g_2 <- readMM("./DataBase/Matrix/bigram_network.mtx")
bigram_name <- readLines("./DataBase/Matrix/bigram_row_name.txt")
rownames(g_2) <- bigram_name
colnames(g_2) <- bigram_name
g_3<- readMM("./DataBase/Matrix/trigram_network.mtx")
trigram_name <- readLines("./DataBase/Matrix/trigram_row_name.txt")
rownames(g_3) <- trigram_name
colnames(g_3) <- trigram_name
g_4 <- readMM("./DataBase/Matrix/quadrigram_network.mtx")
quadrigram_name <- readLines("./DataBase/Matrix/quadrigram_row_name.txt")
rownames(g_4) <- quadrigram_name
colnames(g_4) <- quadrigram_name
remove(uni_name,bigram_name,trigram_name,quadrigram_name)
return(g_1,g_2,g_3,g_4)
}
import_data()
graph_list=c("g_1"=g_1,"g_2"=g_2,"g_3"=g_3,"g_4"=g_4)
import_data <- function(){
g_1 <- readMM("./DataBase/Matrix/unigram_network.mtx")
uni_name <- readLines("./DataBase/Matrix/unigram_row_name.txt")
rownames(g_1) <- uni_name
colnames(g_1) <- uni_name
g_2 <- readMM("./DataBase/Matrix/bigram_network.mtx")
bigram_name <- readLines("./DataBase/Matrix/bigram_row_name.txt")
rownames(g_2) <- bigram_name
colnames(g_2) <- bigram_name
g_3<- readMM("./DataBase/Matrix/trigram_network.mtx")
trigram_name <- readLines("./DataBase/Matrix/trigram_row_name.txt")
rownames(g_3) <- trigram_name
colnames(g_3) <- trigram_name
g_4 <- readMM("./DataBase/Matrix/quadrigram_network.mtx")
quadrigram_name <- readLines("./DataBase/Matrix/quadrigram_row_name.txt")
rownames(g_4) <- quadrigram_name
colnames(g_4) <- quadrigram_name
remove(uni_name,bigram_name,trigram_name,quadrigram_name)
graph_list=c("g_1"=g_1,"g_2"=g_2,"g_3"=g_3,"g_4"=g_4)
return(graph_list)
}
graph_list <- import_data()
graph_list["g_1"]
paste("graph_list$,g_",allpos,sep=""))
paste("graph_list$,g_",allpos,sep="")
allpos=2
paste("graph_list$,g_",allpos,sep="")
paste("graph_list$g_",allpos,sep=""))
paste("graph_list$g_",allpos,sep="")
as.name(paste("graph_list$g_",allpos,sep=""))
eval(as.name(paste("graph_list$g_",allpos,sep="")))
graph_list$g_2
as.name(paste("graph_list$g_",allpos,sep=""))
eval(paste("graph_list$g_",allpos,sep=""))
eval(as.name(paste("graph_list$g_",allpos,sep="")))
eval(as.name(paste("g_",allpos,sep="")))
graph_list[as.name(paste("g_",allpos,sep="")))]
as.name(paste("g_",allpos,sep="")))
as.name(paste("g_",allpos,sep=""))
graph_list[as.name(paste("g_",allpos,sep=""))]
graph_list[eval(as.name(paste("g_",allpos,sep="")))]
(as.name(paste("g_",allpos,sep=""))
(as.name(paste("g_",allpos,sep=""))
as.name(paste("g_",allpos,sep=""))
as.name(paste("g_",allpos,sep="")))
as.name(paste("g_",allpos,sep=""))
paste("g_",allpos,sep="")
graph_list[paste("g_",allpos,sep="")]
library(DT)
install.packages("DT")
library(DT)
the_source <- reactive({word_pred(input$my_source,graph_list)})
shiny::runApp('~/Word_Prediction')
runApp('~/Word_Prediction')
runApp('~/Word_Prediction')
runApp()
runApp('~/Word_Prediction')
getwd()
runApp('~/Word_Prediction')
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp('C:/Users/David/OneDrive/Coursera/Data_dev_PROD/Dev_data_prod/my_app_week4_coursera')
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
g_1 <- readMM("unigram_network.mtx")
uni_name <- readLines("unigram_row_name.txt")
rownames(g_1) <- uni_name
colnames(g_1) <- uni_name
g_2 <- readMM("bigram_network.mtx")
bigram_name <- readLines("bigram_row_name.txt")
rownames(g_2) <- bigram_name
colnames(g_2) <- bigram_name
g_3<- readMM("trigram_network.mtx")
trigram_name <- readLines("trigram_row_name.txt")
rownames(g_3) <- trigram_name
colnames(g_3) <- trigram_name
g_4 <- readMM("quadrigram_network.mtx")
quadrigram_name <- readLines("quadrigram_row_name.txt")
rownames(g_4) <- quadrigram_name
colnames(g_4) <- quadrigram_name
remove(uni_name,bigram_name,trigram_name,quadrigram_name)
graph_list=c("g_1"=g_1,"g_2"=g_2,"g_3"=g_3,"g_4"=g_4)
save.image("C:/Users/David/OneDrive/Coursera/Capstone_Data_science/Word_Prediction/graph_list.RData")
clean_text_DL <- function(my_string){
my_string <- gsub(x=my_string,pattern = "<.*>|@", replacement = "")
my_string <- gsub(x=my_string,"([_])\\1+","\\1", replacement="")
my_string <- quanteda::tokens(my_string,what="word",remove_numbers=T,
remove_punct=T, remove_symbols=T,remove_hyphens=T)
my_string <- quanteda::tokens_tolower(my_string)
my_string <- tokens_wordstem(my_string,language = "english")
my_cleaned_string  <- my_string
return(my_cleaned_string)
}
word_pred <- function(my_source){
all_sub_source <- unlist(clean_text_DL(my_source))
nb_words <- length(all_sub_source)
all_pred <- data.frame()
for (allpos in seq(1,min(nb_words,4))) {
my_sg <- graph_list[paste("g_",allpos,sep="")]
my_ss <- paste(all_sub_source[(nb_words-allpos+1):nb_words],collapse =" ")
if (length(which(rownames(my_sg)==my_ss)!=0)){
my_pred <- sort(my_sg[my_ss,],decreasing = T)[1:4]
my_pred <- data.frame("words"=names(my_pred),"prob"=my_pred,row.names = seq(length(my_pred)))
if (nrow(all_pred) ==0){
all_pred <- my_pred
} else{all_pred <- rbind(all_pred,my_pred)}
}
}
all_pred <- all_pred %>% group_by(words)%>% summarise("prob"=sum(prob)) %>%arrange(desc(prob))
all_pred <- all_pred[1:4,]
return(all_pred)
}
word_pred(input$source)
word_pred("input$source")
my_source="hello you"
all_sub_source <- unlist(clean_text_DL(my_source))
all_sub_source
nb_words <- length(all_sub_source)
all_pred <- data.frame()
my_sg <- graph_list[paste("g_",allpos,sep="")]
allpos=2
my_sg <- graph_list[paste("g_",allpos,sep="")]
my_sg
my_ss <- paste(all_sub_source[(nb_words-allpos+1):nb_words],collapse =" ")
my_ss
(length(which(rownames(my_sg)==my_ss)!=0))
length(which(rownames(my_sg)==my_ss)!=0)
which(rownames(my_sg)==my_ss
which(rownames(my_sg)==my_ss)
length(which(rownames(my_sg)==my_ss))
(length(which(rownames(my_sg)==my_ss))!=0))
(length(which(rownames(my_sg)==my_ss))!=0)
rownames(my_sg)
my_sg[1:10,1:10]
my_sg
rownames(my_sg)
rownames(my_sg)
g_1 <- readMM("unigram_network.mtx")
uni_name <- readLines("unigram_row_name.txt")
rownames(g_1) <- uni_name
colnames(g_1) <- uni_name
rownames(g_1)
g_1
allpos=1
my_sg <- graph_list[paste("g_",allpos,sep="")]
my_ss <- paste(all_sub_source[(nb_words-allpos+1):nb_words],collapse =" ")
rownames(my_sg)
graph_list[paste("g_",allpos,sep="")]
names(my_sg)
rownames(my_sg)
rownames(g_1)
graph_list[paste("g_",allpos,sep="")]
g_1 ==my_sg
eval(as.name(paste("g_",allpos,sep="")))
my_sg <- eval(as.name(paste("g_",allpos,sep="")))
rownames(my_sg)
g_1 <- readMM("unigram_network.mtx")
uni_name <- readLines("unigram_row_name.txt")
rownames(g_1) <- uni_name
colnames(g_1) <- uni_name
g_2 <- readMM("bigram_network.mtx")
bigram_name <- readLines("bigram_row_name.txt")
rownames(g_2) <- bigram_name
colnames(g_2) <- bigram_name
g_3<- readMM("trigram_network.mtx")
trigram_name <- readLines("trigram_row_name.txt")
rownames(g_3) <- trigram_name
colnames(g_3) <- trigram_name
g_4 <- readMM("quadrigram_network.mtx")
quadrigram_name <- readLines("quadrigram_row_name.txt")
rownames(g_4) <- quadrigram_name
colnames(g_4) <- quadrigram_name
remove(uni_name,bigram_name,trigram_name,quadrigram_name)
save.image("C:/Users/David/OneDrive/Coursera/Capstone_Data_science/Word_Prediction/graph_list.RData")
readRDS("graph_list.RData")
getwd()
readRDS("graph_list.RData")
readRDS("graph_list.RData")
load("C:/Users/David/OneDrive/Coursera/Capstone_Data_science/Word_Prediction/graph_list.RData")
load("graph_list.RData")
my_source="hello my friend"
all_sub_source <- unlist(clean_text_DL(my_source))
nb_words <- length(all_sub_source)
all_pred <- data.frame()
clean_text_DL <- function(my_string){
my_string <- gsub(x=my_string,pattern = "<.*>|@", replacement = "")
my_string <- gsub(x=my_string,"([_])\\1+","\\1", replacement="")
my_string <- quanteda::tokens(my_string,what="word",remove_numbers=T,
remove_punct=T, remove_symbols=T,remove_hyphens=T)
my_string <- quanteda::tokens_tolower(my_string)
my_string <- tokens_wordstem(my_string,language = "english")
my_cleaned_string  <- my_string
return(my_cleaned_string)
}
word_pred <- function(my_source,g_1,g_2,g_3,g_4){
all_sub_source <- unlist(clean_text_DL(my_source))
all_sub_source <- unlist(clean_text_DL(my_source))
nb_words <- length(all_sub_source)
nb_words
all_pred <- data.frame()
my_sg <- eval(as.name(paste("g_",allpos,sep="")))
allpos=2
my_sg <- eval(as.name(paste("g_",allpos,sep="")))
my_sg
my_ss <- paste(all_sub_source[(nb_words-allpos+1):nb_words],collapse =" ")
rownames(my_sg)
(length(which(rownames(my_sg)==my_ss))!=0)
names(all_pred) <- c("words","prob")
all_pred <- data.frame()
names(all_pred) <- c("words","prob")
nrow(all_pred)>0
runApp()
runApp()
runApp()
runApp()
library(shiny)
library(shiny)
library(dplyr)
library(stringr)
library(stringdist)
library(textclean)
library(quanteda)
library(igraph)
library(Matrix)
library(doParallel)
library(foreach)
library(DT)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
getwd()
runApp()
runApp()
runApp()
runApp()
runApp()
names(tags)
runApp()
runApp()
runApp()
runApp()
runApp()
getwd()
runApp()
runApp()
getwd()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
